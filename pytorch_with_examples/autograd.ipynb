{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "loaded-pattern",
   "metadata": {},
   "source": [
    "# Autograd\n",
    "\n",
    "- PyTorch의 `autograd` 패키지는 신경망에서 역전파 단계의 연산을 자동화할 수 있음\n",
    "    - 신경망의 역전파 단계를 직접 구현할 필요가 없게 해줌\n",
    "- `x`가 `x.requires_grad=True` 인 Tensor이면 `x.grad`는 어떤 스칼라 값에 대한 x 의 변화도를 갖는 또 다른 Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charitable-biography",
   "metadata": {},
   "source": [
    "## PyTorch: Tensor와 autograd\n",
    "\n",
    "### Example\n",
    "- Fully Connected Network\n",
    "    - 1 hidden layer\n",
    "    - ReLU\n",
    "- 출력과 정답 사이의 유클리드 거리 (Euclidean distance)를 최소화하도록 Optimize\n",
    "- 경사하강법(gradient descent) 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "measured-northeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "네트워크 구성\n",
    "\"\"\"\n",
    "\n",
    "# N : batch size\n",
    "# H : hidden layer의 차원\n",
    "# D_in : 입력의 차원\n",
    "# D_out : 출력의 차원\n",
    "N, H, D_in, D_out = 64, 100, 1000, 10\n",
    "\n",
    "# learning rate\n",
    "lr = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "annoying-thompson",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 28300280.0\n",
      "10 3665564.5\n",
      "20 231582.796875\n",
      "30 70265.34375\n",
      "40 26504.51171875\n",
      "50 11123.322265625\n",
      "60 5001.181640625\n",
      "70 2375.09423828125\n",
      "80 1181.289794921875\n",
      "90 607.9930419921875\n",
      "100 321.8479309082031\n",
      "110 174.64524841308594\n",
      "120 96.58863830566406\n",
      "130 54.264404296875\n",
      "140 30.888309478759766\n",
      "150 17.779647827148438\n",
      "160 10.330820083618164\n",
      "170 6.051975250244141\n",
      "180 3.5700149536132812\n",
      "190 2.1188526153564453\n",
      "200 1.264204502105713\n",
      "210 0.7577446699142456\n",
      "220 0.45608383417129517\n",
      "230 0.2754395008087158\n",
      "240 0.16693682968616486\n",
      "250 0.10146401822566986\n",
      "260 0.0618303157389164\n",
      "270 0.037796102464199066\n",
      "280 0.02321103774011135\n",
      "290 0.014317645691335201\n",
      "300 0.008905576542019844\n",
      "310 0.005594547372311354\n",
      "320 0.0035744633059948683\n",
      "330 0.002320762723684311\n",
      "340 0.001544092781841755\n",
      "350 0.0010544552933424711\n",
      "360 0.000740090967155993\n",
      "370 0.0005362571100704372\n",
      "380 0.00039672659477218986\n",
      "390 0.0003005779581144452\n",
      "400 0.00023131509078666568\n",
      "410 0.00018284382531419396\n",
      "420 0.00014644973271060735\n",
      "430 0.00011903923586942255\n",
      "440 9.804121509660035e-05\n",
      "450 8.178820280591026e-05\n",
      "460 6.988333188928664e-05\n",
      "470 5.9524798416532576e-05\n",
      "480 5.118427725392394e-05\n",
      "490 4.506705226958729e-05\n",
      "\n",
      "0.0010679857805371284\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "x = torch.randn(N, D_in, device=device, dtype=torch.float)\n",
    "y = torch.randn(N, D_out, device=device, dtype=torch.float)\n",
    "\n",
    "# gradient를 계산해야하므로, requires_grad=True\n",
    "w1 = torch.randn(D_in, H, device=device, dtype=torch.float, requires_grad=True)\n",
    "w2 = torch.randn(H, D_out, device=device, dtype=torch.float, requires_grad=True)\n",
    "\n",
    "for t in range(500):\n",
    "    # Forward pass\n",
    "    # 중간의 값들을 가지고 있을 필요가 없음\n",
    "    y_pred = x.mm(w1).clamp(min=0).mm(w2)\n",
    "    \n",
    "    # Loss\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    if t % 10 == 0:\n",
    "        print(t, loss.item())\n",
    "    \n",
    "    # Backprop\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update\n",
    "    with torch.no_grad():\n",
    "        # 가중치들에 대해서는 추적할 필요가 없으므로, torch.no_grad()로 감쌌음\n",
    "        w1 -= lr * w1.grad\n",
    "        w2 -= lr * w2.grad\n",
    "        \n",
    "        # gradient 계산 후, 0으로 비워주기\n",
    "        w1.grad.zero_()\n",
    "        w2.grad.zero_()\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print((y_pred - y).sum().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informational-reward",
   "metadata": {},
   "source": [
    "## PyTorch: 새 autograd 함수 정의하기\n",
    "\n",
    "### `autograd`의 기본(primitive) 연산자\n",
    "- `forward()`\n",
    "    - 입력 Tensor로부터 출력 Tensor를 계산\n",
    "- `backward()`\n",
    "    - 어떤 스칼라 값에 대한 출력 Tensor의 변화도를 전달받고, 동일한 스칼라 값에 대한 입력 Tensor의 변화도를 계산\n",
    "\n",
    "### 사용자 정의 autograd 연산자\n",
    "- 사용자 정의 autograd 연산자는 `torch.autograd.Function` 의 서브클래스(subclass)를 정의하고 `forward` 와 `backward` 함수를 구현하여 정의할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "small-knock",
   "metadata": {},
   "source": [
    "### Example\n",
    "ReLU로 비선형적(nonlinearity)으로 동작하는 사용자 정의 autograd 함수를 정의하여 2-계층 신경망에 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "perceived-mixer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class MyReLU(torch.autograd.Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        # ctx : context object를 의미\n",
    "        # ctx.save_for_backward()로 backward()에서 사용할 정보 저장(cache)\n",
    "        \n",
    "        ctx.save_for_backward(input)\n",
    "        return input.clamp(min=0)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # ctx.saved_tensors로 forward()에서 저장한 정보를 가져올 수 있음\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad_input[input < 0] = 0\n",
    "        return grad_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "directed-greek",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 32125400.0\n",
      "10 1291152.125\n",
      "20 277882.3125\n",
      "30 99130.203125\n",
      "40 41854.14453125\n",
      "50 19480.7890625\n",
      "60 9639.337890625\n",
      "70 4981.47265625\n",
      "80 2650.34765625\n",
      "90 1442.2786865234375\n",
      "100 799.3369140625\n",
      "110 449.7394714355469\n",
      "120 256.4328308105469\n",
      "130 147.93881225585938\n",
      "140 86.25763702392578\n",
      "150 50.77599334716797\n",
      "160 30.15117835998535\n",
      "170 18.046537399291992\n",
      "180 10.879755020141602\n",
      "190 6.602893829345703\n",
      "200 4.031257629394531\n",
      "210 2.474745273590088\n",
      "220 1.5269272327423096\n",
      "230 0.9463138580322266\n",
      "240 0.5888106226921082\n",
      "250 0.36781948804855347\n",
      "260 0.23052042722702026\n",
      "270 0.14490440487861633\n",
      "280 0.09136039018630981\n",
      "290 0.057742055505514145\n",
      "300 0.03661506623029709\n",
      "310 0.02330731973052025\n",
      "320 0.014900961890816689\n",
      "330 0.009598630480468273\n",
      "340 0.0062277596443891525\n",
      "350 0.004094322212040424\n",
      "360 0.0027288866695016623\n",
      "370 0.00185498408973217\n",
      "380 0.001284814323298633\n",
      "390 0.0009048372157849371\n",
      "400 0.0006521072937175632\n",
      "410 0.0004797900328412652\n",
      "420 0.00035890701110474765\n",
      "430 0.0002736023161560297\n",
      "440 0.0002127730695065111\n",
      "450 0.00016793463146314025\n",
      "460 0.00013465895608533174\n",
      "470 0.00010984884283971041\n",
      "480 9.05998022062704e-05\n",
      "490 7.549979636678472e-05\n",
      "\n",
      "-0.0015196676831692457\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "x = torch.randn(N, D_in, device=device, dtype=torch.float)\n",
    "y = torch.randn(N, D_out, device=device, dtype=torch.float)\n",
    "\n",
    "w1 = torch.randn(D_in, H, device=device, dtype=torch.float, requires_grad=True)\n",
    "w2 = torch.randn(H, D_out, device=device, dtype=torch.float, requires_grad=True)\n",
    "\n",
    "for t in range(500):\n",
    "    # Function.apply를 통해 사용자 정의 Function을 적용\n",
    "    relu = MyReLU.apply\n",
    "    \n",
    "    # Forward pass\n",
    "    y_pred = relu(x.mm(w1)).mm(w2) # 사용자 정의 Function인 relu 사용\n",
    "    \n",
    "    # Loss\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    if t % 10 == 0:\n",
    "        print(t, loss.item())\n",
    "    \n",
    "    # Backprop\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update\n",
    "    with torch.no_grad():\n",
    "        w1 -= lr * w1.grad\n",
    "        w2 -= lr * w2.grad\n",
    "        \n",
    "        w1.grad.zero_()\n",
    "        w2.grad.zero_()\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print((y_pred - y).sum().item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
